{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a533853",
   "metadata": {},
   "source": [
    "# Script : tri de dossier\n",
    "\n",
    "## Étape 1 : définir les librairies\n",
    "\n",
    "Les librairies nécessaires ont été définies au fur et à mesure de l'avancement de la construction du programme. \n",
    "\n",
    "Ici, nous avons utilisé **pathlib** afin de pouvoir se promener dans les dossiers et trouver les fichiers\n",
    "\n",
    "Ensuite **docx** et **PyPDF2** ont été utile pour lire les documents et **shutil** pour déplacer les documents\n",
    "\n",
    "Il y a le cas de PDF qui sont des images. Pour cela, il faut procéder à la reconnaissance de ceux-ci. **PyTesseract** lira les images et les convertira en texte, ensuite la librairie **pdf2image** convertira le pdf en images directement avec un outil appelé **poppler**.\n",
    "\n",
    "Il faut activer **sudo** sur l'ordinateur et installer **poppler** et **tesseract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69c56d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docx import Document\n",
    "from PyPDF2 import PdfReader\n",
    "import shutil\n",
    "import pytesseract \n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "POPPLER_PATH = r\"C:\\Program Files\\poppler-25.11.0\\Library\\bin\"  # à adapter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbe146",
   "metadata": {},
   "source": [
    "## Étape 2 : Lecture des documents\n",
    "\n",
    "Nous allons ici déjà définir le dossier, où via deux boucles for et la fonction \"glob\" du package \"Path\" dans pathlib, définir la liste de tous les documents pdf et docx présents dans la boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baba0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "documents = Path(r\"\") # Dossier contenant les documents en vrac\n",
    "\n",
    "dossier_annonce = Path(r\"\") # Dossier où seront déplacés les annonces\n",
    "\n",
    "dossier_CV = Path(r\"\") # Dossier où seront déplacés les CV\n",
    "\n",
    "\n",
    "data=[]\n",
    "for pattern in (\"*.docx\", \"*.pdf\"):\n",
    "    for file in documents.glob(pattern):\n",
    "        data.append(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebacdd",
   "metadata": {},
   "source": [
    "# Étape préliminaire à l'étape 3\n",
    "\n",
    "On va créer une fonction qui traduira les images en texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d431658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_scanned_pdf(path):\n",
    "    pages = convert_from_path(path, dpi=300, poppler_path=POPPLER_PATH)\n",
    "    texte = \"\"\n",
    "    for page in pages:\n",
    "        texte += pytesseract.image_to_string(page, lang=\"fra\") + \"\\n\"\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a721f74",
   "metadata": {},
   "source": [
    "## Étape 3 : Lecture du document, détection du type de document\n",
    "\n",
    "Nous allons créer une première grande boucle pour parcourir toute la liste \"data\". Comme vu, il y a  dedans des chemins vers des PDF ou vers des docx.\n",
    "Nous ouvrons ainsi les docx et pdf selon la méthode nécessaire à cela, et nous récupèrons un texte.\n",
    "\n",
    "Dans ce texte, nous faisons un score de mots clef. Nous allons définir la fréquence de présence de ces mots, selon s'il s'agit d'une annonce ou bien d'un CV. Pour cela j'ai demandé à un LLM les mots les plus fréquents dans les annonces n'étant pas dans les CV et inversement.\n",
    "\n",
    "J'ai personnalisé en rajoutant mon prénom, nom, entreprise dans lesquelles j'ai travaillé, et aussi vérifié pour les accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b41222",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_cv = [\n",
    "        \"experience\", \"competence\", \"formation\", \"profil\", \"curriculum\",\n",
    "        \"contact\", \"diplome\", \"langues\", \"logiciels\"\n",
    "    ]\n",
    "\n",
    "keywords_annonce = [\n",
    "        \"mission\", \"entreprise\", \"poste\", \"responsabilites\",\n",
    "        \"profil recherche\", \"profil recherché\", \"salaire\", \"candidature\",\n",
    "        \"contrat\", \"recrutement\",\"nous\",\"recherchons\" \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca63196",
   "metadata": {},
   "source": [
    "Une fois le score établi, nous allons poser une condition, il faut que le document ait au moins un score de 1 soit dans le nombre de mot de CV présent dans ce document, soit dans l'annonce : j'ai des documents n'étant ni des annonces, ni des CV\n",
    "\n",
    "Si le score_CV est supérieur à celui du score de l'annonce, alors il sera mis stocké dans le dossier CV, sinon, il sera stocké dans le dossier annonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97bfab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 12\n",
      "4 13\n",
      "15 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    \n",
    "    if data[i].suffix.lower() == \".docx\":\n",
    "        texte=\"\\n\".join(p.text for p in Document(data[i]).paragraphs)\n",
    "    \n",
    "    if data[i].suffix.lower() == \".pdf\":\n",
    "        with open(data[i], \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            texte = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "            if texte.strip() ==\"\":\n",
    "                texte=extract_text_from_scanned_pdf(data[i])\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    score_cv=sum(texte.lower().count(mot) for mot in keywords_cv)\n",
    "    score_annonce=sum(texte.lower().count(mot) for mot in keywords_annonce)\n",
    "    print(score_cv, score_annonce)\n",
    "    if score_cv > 1 or score_annonce > 1:\n",
    "\n",
    "        if score_cv < score_annonce:\n",
    "            shutil.move(str(data[i]), str(dossier_annonce))\n",
    "        \n",
    "        elif score_cv >= score_annonce:\n",
    "            shutil.move(str(data[i]), str(dossier_CV))\n",
    "    \n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3bac3",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Le code est fonctionnel.\n",
    "\n",
    "Points d'amélioration : \n",
    " - Il me reste les lettres de motivations :-)\n",
    " - Certaines annonces n'ont pas bougé : certaines étant en anglais, d'autres usant d'autres mots, et il se peut qu'il y ait des encodages parfois différent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
